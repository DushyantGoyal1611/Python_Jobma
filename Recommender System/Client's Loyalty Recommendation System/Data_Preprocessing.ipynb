{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14870ac9-f51a-447f-83ec-a1e393e36259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "# Data Encoding and Scaling\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import set_config\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Natural Language Processing(NLP)\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# Word Embedding\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b27c1ff5-300e-4cab-83df-0aed765a1a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ad80787-b342-462a-8b26-91856bd35292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dushyant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dushyant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2098b5c6-dbe5-4357-837a-ee5800c74470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a06d0c6f-9f10-4469-a9f2-5fffc21d39c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' premium_plan, jobma_catcher_creation, \\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Columns to recheck '''\n",
    "''' premium_plan, jobma_catcher_creation, \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5818144d-b25f-479a-ae6e-a4c8ccbd0aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_collection.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9a4e756-b582-4fcb-aab0-3965d01f4e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\njobma_catcher_company, org_type, jobma_catcher_indus, jobma_job_title, slug, jobma_job_functional_areas, jobma_job_keywords, \\n\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' to create tags '''\n",
    "'''\n",
    "jobma_catcher_company, org_type, jobma_catcher_indus, jobma_job_title, slug, jobma_job_functional_areas, jobma_job_keywords, \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7ff1d4a-0ac9-4533-a6dd-774a0235301d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 179549 entries, 0 to 179548\n",
      "Data columns (total 60 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   jobma_catcher_id                179549 non-null  int64  \n",
      " 1   credit_amount                   143663 non-null  float64\n",
      " 2   wallet_amount                   179549 non-null  float64\n",
      " 3   subscription_type_x             179549 non-null  object \n",
      " 4   plan_type                       179545 non-null  object \n",
      " 5   is_unlimited                    179546 non-null  object \n",
      " 6   premium_storage_x               179549 non-null  int64  \n",
      " 7   premium_plan                    179521 non-null  object \n",
      " 8   subscription_amount             179549 non-null  float64\n",
      " 9   credit_given                    179549 non-null  int64  \n",
      " 10  premium_storage_y               179549 non-null  int64  \n",
      " 11  currency_val                    179549 non-null  float64\n",
      " 12  payment_mode                    179520 non-null  float64\n",
      " 13  status                          179549 non-null  int64  \n",
      " 14  payment_status                  179271 non-null  float64\n",
      " 15  number_of_transactions          179549 non-null  int64  \n",
      " 16  jobma_catcher_company           179549 non-null  object \n",
      " 17  org_type                        3755 non-null    object \n",
      " 18  jobma_catcher_indus             169735 non-null  object \n",
      " 19  jobma_catcher_title             179549 non-null  int64  \n",
      " 20  jobma_catcher_otype             172776 non-null  float64\n",
      " 21  jobma_catcher_creation          179549 non-null  object \n",
      " 22  jobma_catcher_type              179549 non-null  int64  \n",
      " 23  jobma_catcher_sub_accounts      0 non-null       float64\n",
      " 24  is_premium                      179549 non-null  int64  \n",
      " 25  jobma_catcher_parent            179549 non-null  int64  \n",
      " 26  jobma_catcher_is_deleted        179549 non-null  object \n",
      " 27  jobma_verified                  179549 non-null  int64  \n",
      " 28  data_access                     179549 non-null  int64  \n",
      " 29  subscription_status             179549 non-null  int64  \n",
      " 30  interview_rate                  179549 non-null  float64\n",
      " 31  live_interview_credit           179549 non-null  float64\n",
      " 32  pre_recorded_credit             179549 non-null  float64\n",
      " 33  ai_live_interview_credit        179549 non-null  float64\n",
      " 34  credit_value                    179549 non-null  int64  \n",
      " 35  interview_cost_type             179549 non-null  int64  \n",
      " 36  subscription_type_y             179549 non-null  int64  \n",
      " 37  phone_call_cost_type            63127 non-null   float64\n",
      " 38  jobma_support_rtc               179549 non-null  int64  \n",
      " 39  interview_question              179549 non-null  int64  \n",
      " 40  video_recording_suppport        179549 non-null  int64  \n",
      " 41  sing_up_canditate_after_apply   179549 non-null  int64  \n",
      " 42  referral_credit                 179549 non-null  int64  \n",
      " 43  company_size                    179549 non-null  object \n",
      " 44  jobma_auto_recording_status     179549 non-null  int64  \n",
      " 45  jobma_scenario_question_status  179549 non-null  int64  \n",
      " 46  number_of_kits                  179549 non-null  float64\n",
      " 47  number_of_invitations           179549 non-null  int64  \n",
      " 48  jobma_job_title                 179301 non-null  object \n",
      " 49  slug                            179301 non-null  object \n",
      " 50  jobma_job_type                  64397 non-null   object \n",
      " 51  jobma_job_functional_areas      1680 non-null    object \n",
      " 52  jobma_job_keywords              11733 non-null   object \n",
      " 53  jobma_job_currency              11111 non-null   object \n",
      " 54  jobma_job_company_profile       103800 non-null  object \n",
      " 55  jobma_job_apply_count           0 non-null       float64\n",
      " 56  jobma_job_view_count            0 non-null       float64\n",
      " 57  approval                        179548 non-null  float64\n",
      " 58  job_subscription_status         179549 non-null  int64  \n",
      " 59  applicant_count                 290 non-null     float64\n",
      "dtypes: float64(18), int64(25), object(17)\n",
      "memory usage: 82.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1b77de0-0349-4975-b503-e61f000d796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['subscription_type_x',\n",
    "         'premium_storage_y',\n",
    "         'currency_val',\n",
    "         'jobma_catcher_sub_accounts',\n",
    "         'jobma_job_company_profile'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7faa1e9-9c8c-452c-b104-dd3c9761ac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['plan_type'].fillna('No', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0082ff70-7f35-4d0f-ab7a-f43193a3fef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_unlimited'].fillna('No', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1574ca6-690b-4014-928a-08161cd5bc21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179549, 55)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45616546-626e-46ab-87a8-c032741a8c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df.columns:\n",
    "#     if df[col].dtype == object:\n",
    "#         if df[col].astype(str).str.contains('<', na=False).any():\n",
    "#             print(f\"Column '{col}' contains '<'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "326b8616-29cb-4a7c-96bb-8b2042ca38ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This Function is to fill all missing values (if col is int then 0, if col is float then 0.0 and if col is object then 'Unkmown') '''\n",
    "\n",
    "def fill_missing_values(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == np.int64:\n",
    "            df[col].fillna(0, inplace=True)\n",
    "        elif df[col].dtype == np.float64:\n",
    "            df[col].fillna(0.0, inplace=True)\n",
    "        elif df[col].dtype == object:\n",
    "            df[col].fillna('Unknown', inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f1ef077-c240-42a8-89e6-bc1cca81e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(df):\n",
    "    df = df.copy()\n",
    "    label_encoders = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == object:\n",
    "            le = LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41500ee3-f995-4d94-b91d-3f3c6d580b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tags'] = (\n",
    "    df['jobma_catcher_company'].astype(str) + \" \"+\n",
    "    df['org_type'].astype(str) + \" \"+\n",
    "    df['jobma_catcher_indus'].astype(str) + \" \"+\n",
    "    df['jobma_job_title'].astype(str) + \" \"+\n",
    "    df['slug'].astype(str) + \" \"+\n",
    "    df['jobma_job_functional_areas'].astype(str) + \" \"+\n",
    "    df['jobma_job_keywords'].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "424c7020-ab03-4936-9ff7-31d24edf87c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['org_type',\n",
    "        'jobma_catcher_indus',\n",
    "        'jobma_job_title',\n",
    "        'slug',\n",
    "        'jobma_job_functional_areas',\n",
    "        'jobma_job_keywords'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96041280-920d-462e-bbb5-4b747f0bb1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Select Source International nan nan business partner training business-partner-training HR / Administration / IR Training, \"Instructional Design\",  \"Curriculum design\", \"java'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1,'tags']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a76e6c-8a81-4eae-b095-4209ebcba058",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "**Note: Use Lemmatization for more accuracy**\n",
    "\n",
    "To normalize words and reduce them to their root forms, we will apply **stemming**. This helps in handling variations of words and improves text processing efficiency for machine learning models.  \n",
    "(e.g., \"running\" → \"run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479339ad-a1a1-4a02-9705-31b075db5263",
   "metadata": {},
   "source": [
    "**Currently using Lemmatization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06779dec-0e0b-41bc-9f73-3066804d31bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa25c29b-005d-4f95-8075-18d36b1aa297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77e3411b-b139-46cf-8021-6a5c16df86d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def formatting(text):\n",
    "#     if isinstance(text, list):\n",
    "#         text = \" \".join(text)\n",
    "\n",
    "#     words = word_tokenize(text.lower())\n",
    "#     filtered_words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "#     return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ff2d4b7-0172-446c-983b-6a018a7fc104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    if isinstance(text, list):\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    words = word_tokenize(text.lower())\n",
    "    filtered_words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0160fc33-0d08-4136-8edf-cf81dc377231",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Applying Stopwords Removal and Lemmatization'''\n",
    "\n",
    "df['tags'] = df['tags'].apply(formatting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c593930f-7dfb-406f-bce1-254cb4e8aeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1,'tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b29968-9c72-4e47-909f-7cbaf93482e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(text):\n",
    "    words = text.split()\n",
    "    seen = set()\n",
    "    unique_words = []\n",
    "\n",
    "    for word in words:\n",
    "        if word not in seen:\n",
    "            seen.add(word)\n",
    "            unique_words.append(word)\n",
    "\n",
    "    return \" \".join(unique_words)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af07baf5-88f2-4f5b-9780-e13588c17669",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Removing Duplicates from tags '''\n",
    "\n",
    "df['tags'] = df['tags'].apply(remove_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2f40e8-9ebd-475f-8780-4a9b28581b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1,'tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d28f42-d7c2-468a-b640-2671aabb703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tags'] = df['tags'].str.replace('/', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3785336-ca7a-4ed0-a869-8981e3e82cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1,'tags']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36ff167-c553-480b-bb4a-cfd53cf4de63",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Word Embeddings\n",
    "**Note: Use Contextual Embeddings for More Accuracy**\n",
    "\n",
    "To represent words in a numerical format while preserving their meaning and relationships, we will apply **word embeddings**. This helps in capturing semantic similarities and improving machine learning model performance.\n",
    "(e.g., \"king\" → similar to \"queen\" but different from \"apple\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b508e52-7969-4652-bbce-db52f704510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = [tag.split() for tag in df['tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01dcb62-4abf-4615-8ea2-fcb74ba6be1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec model\n",
    "# w2v_model = Word2Vec(sentences, vector_size=16, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690f9592-6b35-46a0-a57b-8077295beebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to convert text into an average word embedding\n",
    "# def text_to_embedding(text):\n",
    "#     words = text.split()\n",
    "#     embeddings = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
    "#     return np.mean(embeddings, axis=0) if embeddings else np.zeros(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94160e8d-634c-466c-af22-ca1e923eaae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_embeddings = np.array([text_to_embedding(text) for text in df['tags']])\n",
    "# text_embeddings_df = pd.DataFrame(text_embeddings, columns=[f'emb_{i}' for i in range(16)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894b3fea-beb7-457b-9b2a-27f279490079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.join(text_embeddings_df, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbe33ac-23d6-4d10-9b83-641916c82287",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vector_size=16):\n",
    "        self.vector_size = vector_size\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.model = Word2Vec(sentences=X, vector_size=self.vector_size, window=5, min_count=1, workers=4)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.apply(lambda words:\n",
    "                      np.mean([self.model.wv[word] for word in words if word in self.model.wv]\n",
    "                             or [np.zeros(self.vector_size)], axis=0)\n",
    "                      ).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db47964e-ad9b-4c0c-a28d-8ba99c3dabe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop('tags', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4d91d9-aa03-4707-9c10-a3bde9deca0f",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e132d3-595c-49ac-9faa-f7b6d9b08381",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b354b88-8dec-43a7-bdfd-6c7828382ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing_pipeline = Pipeline([\n",
    "#     ('fill_missing_values', FunctionTransformer(fill_missing_values, validate=False)),\n",
    "#     ('label_encoder', FunctionTransformer(label_encoder, validate=False)),\n",
    "#     ('scaler', StandardScaler()),\n",
    "#     # ('pca', PCA(n_components=0.95))\n",
    "#     ('formatting', FunctionTransformer(formatting, validate=False)),\n",
    "#     ('remove_duplicates', FunctionTransformer(remove_duplicates, validate=False)),\n",
    "#     ('word_embedding', Word2VecTransformer(vector_size=16))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e15ef21-0093-44cb-8d21-ea90ede36eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_pipeline = Pipeline([\n",
    "    ('fill_missing_values', FunctionTransformer(fill_missing_values, validate=False)),\n",
    "    ('label_encoder', FunctionTransformer(label_encoder, validate=False)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    # ('pca', PCA(n_components=0.95))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bb0330-1ed2-48b9-b032-68c62b139ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = Pipeline([\n",
    "    ('formatting', FunctionTransformer(formatting, validate=False)),\n",
    "    ('remove_duplicates', FunctionTransformer(remove_duplicates, validate=False)),\n",
    "    ('word_embedding', Word2VecTransformer(vector_size=16))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5842c014-dd47-457e-b53b-f13ad26663ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Combining both numerical_pipeline and text_pipeline '''\n",
    "preprocessing_pipeline = ColumnTransformer(transformers=[\n",
    "    ('text', text_pipeline, 'tags'),\n",
    "    ('tabular', numerical_pipeline, [col for col in df.columns if col != 'tags'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a574b36-3f3f-4263-afae-83506a84fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Visualize the Pipeline '''\n",
    "\n",
    "set_config(display='diagram')\n",
    "preprocessing_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8596659-f6fd-4d03-b830-ae90c5f40633",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914b941a-f6b5-49f6-bdbf-939a4c1f1123",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ee2412-a6e9-46a0-966f-a4e5a31c7d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e7bdfa-071b-4165-a79c-4ac799628937",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Length of X_train: {len(X_train)}')\n",
    "print(f'Length of X_test: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0876ae-932a-40fe-b4f6-02648bda2b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train), type(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f6b127-5827-4387-a9a0-c06b5831ed6f",
   "metadata": {},
   "source": [
    "# Fit Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f30179d-6003-41a2-89ef-0a55545f91e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cb7744-07cb-4afb-832b-8ba6438de6d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = preprocessing_pipeline.fit_transform(X_train)\n",
    "X_test =  preprocessing_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb40ef4-c81b-4eb4-bfe9-38ce5f356856",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Convert into Tensors '''\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a866d0-6464-49e4-ac14-5e9c43111c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train_tensor), type(X_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5349f2d0-6d2f-44b0-9517-aecabeea0fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train_tensor), len(X_test_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2997ddc1-6638-481e-9b5d-24ea19612cc3",
   "metadata": {},
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c28054-1ea2-46af-9912-181daa663844",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86ae036-0025-4a5b-b2e7-8a79f3765f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CustomDataset(X_train_tensor)\n",
    "test_data = CustomDataset(X_test_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39704b49-ef69-44e7-ade6-fd5543ed8e9b",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2d8bd6-bba2-430b-b976-01e5108d995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bad7d96-3ad4-491d-9439-0a12f915db2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd87d70-6ef0-4cc2-9c94-c651ea153c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f35a7b-9003-40eb-81d8-33146ac0627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6789fc65-5e02-4a2e-b49e-e525178f8d62",
   "metadata": {},
   "source": [
    "# Define a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d957f086-9840-483a-9b46-8f2e648e5801",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client_Recommendation_Model(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super().__init__()\n",
    "        ''' Encoder (Compression) '''\n",
    "        # Shrinks job data into a small hidden representation (like a summary).\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_shape, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32)\n",
    "        )\n",
    "\n",
    "        ''' Decoder (Reconstruction) '''\n",
    "        # Tries to rebuild the original job data from that compressed version.\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, input_shape),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3285ff-7ef7-4542-870b-c4f8d5b0e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b35a2b3-afdf-4d1f-ad46-2bfeadc0d410",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Initializing the model '''\n",
    "input_shape = X_train.shape[1]\n",
    "\n",
    "model_1 = Client_Recommendation_Model(input_shape)\n",
    "model_1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856fe9be-d219-4ff8-a0a4-d2926f7fea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Important Parameters '''\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1773cd-8c0d-44c0-9fca-5144cb8bc20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Loss Function and Optimizer '''\n",
    "cosine_loss_function = nn.CosineEmbeddingLoss()\n",
    "mse_loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_1.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a9d289-2678-4814-b785-e2ddd29d36aa",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b103d3-8e6e-4a6d-982f-74fb62544d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model:torch.nn.Module,\n",
    "               dataloader:torch.utils.data.DataLoader,\n",
    "               mse_loss_function:torch.nn.Module,\n",
    "               cosine_loss_function:torch.nn.Module,\n",
    "               optimizer:torch.optim.Optimizer,\n",
    "              device:torch.device):\n",
    "    \n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    epoch_total_loss = 0\n",
    "\n",
    "    for batch_X in dataloader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        encoded, decoded = model(batch_X)  # Forward pass\n",
    "\n",
    "        ''' Compute Loss '''\n",
    "        mse_loss = mse_loss_function(decoded, batch_X)  # Reconstruction Loss\n",
    "\n",
    "        batch_size = encoded.shape[0]\n",
    "        target_labels = torch.ones(batch_size, device=device)\n",
    "\n",
    "        permuted_indices = torch.randperm(batch_size, device=device)\n",
    "        encoded_shuffled = encoded[permuted_indices]\n",
    "\n",
    "        cosine_loss = cosine_loss_function(encoded, encoded_shuffled, target_labels) # Similarity Loss\n",
    "        total_loss = mse_loss + cosine_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_total_loss += total_loss.item()\n",
    "\n",
    "    training_loss = epoch_total_loss / len(dataloader)\n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dcad32-ac63-4599-b2c1-c38274ec1eca",
   "metadata": {},
   "source": [
    "# Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c18445c-ffd6-4bce-9a46-c6fcc599129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model:torch.nn.Module,\n",
    "              dataloader:torch.utils.data.DataLoader,\n",
    "              mse_loss_function:torch.nn.Module,\n",
    "              cosine_loss_function:torch.nn.Module,\n",
    "              device:torch.device\n",
    "             ):\n",
    "\n",
    "    epoch_total_loss = 0\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch_X in dataloader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            encoded, decoded = model(batch_X)  # Forward pass\n",
    "\n",
    "            ''' Compute Loss '''\n",
    "            mse_loss = mse_loss_function(decoded, batch_X)  # Reconstruction Loss\n",
    "    \n",
    "            batch_size = encoded.shape[0]\n",
    "            target_labels = torch.ones(batch_size, device=device)\n",
    "\n",
    "            # Compare each encoded job to another shuffled job\n",
    "            permuted_indices = torch.randperm(batch_size, device=device)\n",
    "            encoded_shuffled = encoded[permuted_indices]\n",
    "\n",
    "            cosine_loss = cosine_loss_function(encoded, encoded_shuffled, target_labels)\n",
    "            total_loss = mse_loss + cosine_loss\n",
    "            \n",
    "            epoch_total_loss += total_loss.item()\n",
    "\n",
    "        testing_loss = epoch_total_loss / len(dataloader)\n",
    "        return testing_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb50ff45-8039-487e-a240-63f49bb5f6e2",
   "metadata": {},
   "source": [
    "# Combining Training and Testing Loop into evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef5c88a-e103-4e5c-ad16-0b657dbc7524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(model:torch.nn.Module,\n",
    "#              train_dataloader:torch.utils.data.DataLoader,\n",
    "#              test_dataloader:torch.utils.data.DataLoader,\n",
    "#              mse_loss_function:torch.nn.Module,\n",
    "#              cosine_loss_function:torch.nn.Module,\n",
    "#              device:torch.device,\n",
    "#              epochs:int = 5\n",
    "#             ):\n",
    "    \n",
    "#     results = {'training_loss':[],\n",
    "#               'testing_loss':[]}\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         training_loss = train_step(model=model,\n",
    "#                                    dataloader=train_dataloader,\n",
    "#                                    mse_loss_function=mse_loss_function,\n",
    "#                                    cosine_loss_function=cosine_loss_function,\n",
    "#                                    optimizer=optimizer,\n",
    "#                                    device=device\n",
    "#                                   )\n",
    "\n",
    "#         testing_loss = test_step(model=model,\n",
    "#                                    dataloader=test_dataloader,\n",
    "#                                    mse_loss_function=mse_loss_function,\n",
    "#                                    cosine_loss_function=cosine_loss_function,\n",
    "#                                  device=device\n",
    "#                                   )\n",
    "\n",
    "#         results['training_loss'].append(training_loss)\n",
    "#         results['testing_loss'].append(testing_loss)\n",
    "\n",
    "#         print(f'Epoch {epoch+1}/{epochs} | Training Loss: {training_loss:.5f} | Testing Loss: {testing_loss:.5f}')\n",
    "\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43307d79-5a52-447c-be0f-b0c6b3921efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model:torch.nn.Module,\n",
    "             train_dataloader:torch.utils.data.DataLoader,\n",
    "             test_dataloader:torch.utils.data.DataLoader,\n",
    "             mse_loss_function:torch.nn.Module,\n",
    "             cosine_loss_function:torch.nn.Module,\n",
    "             device:torch.device,\n",
    "             epochs:int = 5,\n",
    "             patience: int = 5\n",
    "            ):\n",
    "    \n",
    "    results = {'training_loss':[],\n",
    "              'testing_loss':[]}\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        training_loss = train_step(model=model,\n",
    "                                   dataloader=train_dataloader,\n",
    "                                   mse_loss_function=mse_loss_function,\n",
    "                                   cosine_loss_function=cosine_loss_function,\n",
    "                                   optimizer=optimizer,\n",
    "                                   device=device\n",
    "                                  )\n",
    "\n",
    "        testing_loss = test_step(model=model,\n",
    "                                   dataloader=test_dataloader,\n",
    "                                   mse_loss_function=mse_loss_function,\n",
    "                                   cosine_loss_function=cosine_loss_function,\n",
    "                                 device=device\n",
    "                                  )\n",
    "\n",
    "        results['training_loss'].append(training_loss)\n",
    "        results['testing_loss'].append(testing_loss)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs} | Training Loss: {training_loss:.5f} | Testing Loss: {testing_loss:.5f}')\n",
    "\n",
    "        if testing_loss < best_loss:\n",
    "            best_loss = testing_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(f\"Early Stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace6fd82-4984-45a8-9154-65e6c2a92f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model_1_results = evaluate(model=model_1,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        test_dataloader=test_dataloader,\n",
    "                        mse_loss_function=mse_loss_function,\n",
    "                        cosine_loss_function=cosine_loss_function,\n",
    "                        device=device,\n",
    "                        epochs=epochs,\n",
    "                        patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fff44a0-ff87-4eea-b125-48c051509cc1",
   "metadata": {},
   "source": [
    "# Loss and Accuracy Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3205188f-3405-4f80-b1b5-320c5fa0da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(len(model_1_results['training_loss']))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, model_1_results['training_loss'], label='Training Loss')\n",
    "plt.plot(epochs, model_1_results['testing_loss'], label='Testing Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training VS Testing Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5a6cb1-63a9-4cbd-b532-c8645061c177",
   "metadata": {},
   "outputs": [],
   "source": [
    ";klnbhjgvcfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae72ff5c-66ae-4acf-8fb8-434038755354",
   "metadata": {},
   "source": [
    "# Recommending 5 Top Clients (Based on Loyalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5bf554-686f-4fb9-b0a0-d2994bfc8bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_pref = {\n",
    "    'Age' : 22\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533d5103-64e4-490b-bfc5-5d976e27e627",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_pref_df = pd.DataFrame([company_pref])\n",
    "type(company_pref_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcf5d9e-fba2-4e01-b9dc-55be7f2ef5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_pref_transformed = preprocessing_pipeline.transform(company_pref_df)\n",
    "type(company_pref_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4b7843-07b0-418e-a8bd-e3898e8bfab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_pref_tensor = torch.tensor(company_pref_transformed, torch.float32)\n",
    "type(company_pref_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3827ec6-b739-4714-bc2c-145e6ada8b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_pref_tensor.shape, X_test_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9fc6a1-2795-4122-a5b3-f2fd6a8e575e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
