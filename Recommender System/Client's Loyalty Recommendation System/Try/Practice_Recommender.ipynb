{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b26263a-45a8-44f7-9165-fa0b62f6bcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis Notebook includes:-\\n\\n-> Exception Handling\\n-> Multiple Pipelines\\n-> Database Connection\\n-> Data Fetching from SQL\\n-> Modularization or Functional Decomposition\\n-> AutoEncoder and Model Training\\n-> Recommendation Function\\n\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This Notebook includes:-\n",
    "\n",
    "-> Exception Handling\n",
    "-> Multiple Pipelines\n",
    "-> Database Connection\n",
    "-> Data Fetching from SQL\n",
    "-> Modularization or Functional Decomposition\n",
    "-> AutoEncoder and Model Training\n",
    "-> Recommendation Function\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c51e8dc-c33a-43c9-91a2-1f65fb92965d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Data Encoding and Scaling\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d550f087-874a-4655-8c32-ca5624a62c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d67f28be-4ef9-44d1-ba26-7acffbd5fc7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading .env file into my python code\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c27c48a2-eb27-422d-9ab9-b71b280d6c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection():\n",
    "    print('creating connection with DB')\n",
    "    try:\n",
    "        user = os.getenv(\"DB_USER\")\n",
    "        raw_password = os.getenv(\"DB_PASSWORD\")\n",
    "        password = quote_plus(raw_password)\n",
    "        host = os.getenv(\"DB_HOST\")\n",
    "        port = os.getenv(\"DB_PORT\")\n",
    "        db = os.getenv(\"DB_NAME\")\n",
    "    \n",
    "        # Credentials of mySQL connection\n",
    "        connection_string = f\"mysql+pymysql://{user}:{password}@{host}:{port}/{db}\"\n",
    "        engine = create_engine(connection_string)\n",
    "        print('connection created successfully')\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        print(f'Error creating connection with DB: {e}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c54cad2-da3b-4a26-a3f1-be6538558e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(engine,catcher_only=False):\n",
    "    print('creating DFs=============')\n",
    "    try:\n",
    "        if engine is not None:\n",
    "            if catcher_only:\n",
    "                print('Catcher DF is requested')\n",
    "                catcher_df = pd.read_sql(\"Select jobma_catcher_id, jobma_catcher_parent, subscription_status, company_size FROM jobma_catcher where jobma_verified = '1' \", con=engine) \n",
    "                return catcher_df\n",
    "            print(\"Wallet DF\")\n",
    "            wallet_df = pd.read_sql(\"Select catcher_id AS jobma_catcher_id, is_unlimited FROM wallet where is_unlimited <> '' \", con=engine)\n",
    "            print(\"Subscription DF\")\n",
    "            subscription_df = pd.read_sql(\"Select catcher_id AS jobma_catcher_id, currency, subscription_amount FROM subscription_history\", con=engine)\n",
    "            print(\"Invitation DF\")\n",
    "            invitation_df = pd.read_sql(\"Select jobma_catcher_id, jobma_interview_mode, jobma_interview_status FROM jobma_pitcher_invitations\", con=engine)\n",
    "            print(\"Job posting DF\")\n",
    "            job_posting_df = pd.read_sql(\"Select jobma_catcher_id FROM jobma_employer_job_posting\", con=engine)\n",
    "            print(\"kit DF\")\n",
    "            kit_df = pd.read_sql(\"Select catcher_id AS jobma_catcher_id FROM job_assessment_kit\", con=engine)\n",
    "            print('Login DF')\n",
    "            login_df = pd.read_sql(\"Select jobma_user_id AS jobma_catcher_id, jobma_last_login FROM jobma_login where jobma_role_id = 3\",con=engine)\n",
    "            \n",
    "            # Closing the Connection\n",
    "            engine.dispose()\n",
    "            return wallet_df, subscription_df,invitation_df,job_posting_df,kit_df,login_df\n",
    "        else:\n",
    "            print('Engine is not Supporting (Problem in create_df)')\n",
    "    except Exception as e:\n",
    "        print(f'Error in create_df: {e}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b13d081-936f-4124-8ce4-aef3122ab5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catcher_df\n",
    "def fetching_catcher_df(catcher_df):\n",
    "    print(\"Processing catcher DF\")\n",
    "    try:\n",
    "        catcher_df['subscription_status'] = catcher_df['subscription_status'].replace({'0':0, '1':1, '2':0})\n",
    "        return catcher_df\n",
    "    except KeyError as e:\n",
    "        print(f'Key Not Found: {e}')\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bac1fc3-a740-473a-9b6b-d6b04a9366c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wallet_df\n",
    "def fetching_wallet_df(wallet_df):\n",
    "    print(\"Processing wallet DF\")\n",
    "    try:\n",
    "        wallet_df['is_unlimited'] = wallet_df['is_unlimited'].replace({'0':0, '1':1})\n",
    "        wallet_df.drop_duplicates(inplace=True)\n",
    "        return wallet_df\n",
    "    except KeyError as e:\n",
    "        print(f'Key Not Found: {e}')\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "316bcb04-f490-46ae-ad59-bdf5305d6b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subscription_df\n",
    "def fetching_subscription_df(subscription_df):\n",
    "    print(\"Processing subscription DF\")\n",
    "    try:\n",
    "        subscription_df.loc[subscription_df['currency'] == '1', 'subscription_amount'] /= 85.23\n",
    "        subscription_df = subscription_df.groupby('jobma_catcher_id').agg(\n",
    "            subscription_amount_in_dollars = ('subscription_amount', 'sum'),\n",
    "            number_of_subscriptions = ('subscription_amount', 'count'),\n",
    "        ).reset_index()\n",
    "        subscription_df['subscription_amount_in_dollars'] = subscription_df['subscription_amount_in_dollars'].round(3)\n",
    "        subscription_df.drop_duplicates(inplace=True)\n",
    "        return subscription_df\n",
    "    except KeyError as e:\n",
    "        print(f'Key Not Found: {e}')\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4bbafa5-800b-4930-a617-c9b89d9a0872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# login_df\n",
    "def fetching_login_df(login_df):\n",
    "    print(\"Processing login DF\")\n",
    "\n",
    "    # Calculating Number of Gaps between last login and today\n",
    "    try:\n",
    "        login_df['jobma_last_login'] = pd.to_datetime(login_df['jobma_last_login'], errors='coerce')\n",
    "        login_df['activity_duration'] = (pd.Timestamp('today') - login_df['jobma_last_login']).dt.days\n",
    "        login_df['activity_duration'].fillna(370, inplace=True)\n",
    "        login_df['activity_duration'] = login_df['activity_duration'].astype(int)\n",
    "    \n",
    "        # Binning\n",
    "        bins = [-1,7,30,90,180,365,float('inf')]\n",
    "        labels = ['Less than 1 Week', '1-4 Weeks', '1-3 Months', '3-6 Months', '6-12 Months', 'More than 1 Year']\n",
    "        login_df['activity_duration'] = pd.cut(login_df['activity_duration'], bins=bins, labels=labels)\n",
    "        login_df = login_df[['jobma_catcher_id', 'activity_duration']]\n",
    "        return login_df\n",
    "    except KeyError as e:\n",
    "        print(f'Key Not Found: {e}')\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef06aa61-60dc-4c90-a5e5-bf0a4d372a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetching_features(invitation_df, job_posting_df, kit_df):\n",
    "    print(\"Fetching features\")\n",
    "\n",
    "    try:\n",
    "        job_posting_df['job_posted'] = job_posting_df['jobma_catcher_id'].map(job_posting_df['jobma_catcher_id'].value_counts())\n",
    "        kit_df['number_of_kits'] = kit_df['jobma_catcher_id'].map(kit_df['jobma_catcher_id'].value_counts())\n",
    "    \n",
    "        invitation_df['number_of_invitations'] = invitation_df['jobma_catcher_id'].map(invitation_df['jobma_catcher_id'].value_counts())\n",
    "        invitation_df = invitation_df[invitation_df['jobma_interview_mode'].isin(['1', '2'])].copy()\n",
    "        interview_counts = invitation_df.groupby(['jobma_catcher_id', 'jobma_interview_mode']).size().unstack(fill_value=0)\n",
    "        interview_counts = interview_counts.rename(columns={'1': 'number_of_recorded_interviews', '2': 'number_of_live_interviews'})\n",
    "        invitation_df = invitation_df.merge(interview_counts, on='jobma_catcher_id', how='left')\n",
    "    \n",
    "        #------\n",
    "        invitation_df = invitation_df[invitation_df['jobma_interview_status'] != '0']\n",
    "        invitation_df['interview_completed'] = invitation_df['jobma_catcher_id'].map(invitation_df['jobma_catcher_id'].value_counts())\n",
    "        invitation_df.drop(['jobma_interview_mode', 'jobma_interview_status'], axis=1, inplace=True)\n",
    "        #------\n",
    "        invitation_df = invitation_df.drop_duplicates()\n",
    "    \n",
    "        job_posting_df = job_posting_df[['jobma_catcher_id', 'job_posted']].drop_duplicates()\n",
    "        kit_df = kit_df[['jobma_catcher_id', 'number_of_kits']].drop_duplicates()\n",
    "    \n",
    "        return invitation_df, job_posting_df, kit_df\n",
    "    except Exception as e:\n",
    "        print(f'Error in fetching_features: {e}')\n",
    "        return pd.DataFrame(),pd.DataFrame(),pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77520251-4d35-4303-9973-529bedad215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merging_df(catcher_df, wallet_df, subscription_df, invitation_df, job_posting_df, kit_df, login_df):\n",
    "    print(\"Merging DFs\")\n",
    "    try:\n",
    "        final_df = catcher_df.copy()\n",
    "    \n",
    "        # Left join each table one by one\n",
    "        try:\n",
    "            if isinstance(final_df, pd.DataFrame):\n",
    "                final_df = final_df.merge(login_df, on='jobma_catcher_id', how='left')\n",
    "                final_df = final_df.merge(wallet_df, on='jobma_catcher_id', how='left')\n",
    "                final_df = final_df.merge(subscription_df, on='jobma_catcher_id', how='left')\n",
    "                final_df = final_df.merge(invitation_df, on='jobma_catcher_id', how='left')\n",
    "                final_df = final_df.merge(job_posting_df, on='jobma_catcher_id', how='left')\n",
    "                final_df = final_df.merge(kit_df, on='jobma_catcher_id', how='left')\n",
    "                final_df.drop_duplicates(inplace=True)\n",
    "            else:\n",
    "                raise TypeError('Final DF is not a DataFrame')\n",
    "        except TypeError as e:\n",
    "            print(f'Error in Merging DFs: {e}')\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f'Error Merging DataFrames: {e}')\n",
    "            return None\n",
    "    \n",
    "        # For Total Sub\n",
    "        try:\n",
    "            sub_counts = final_df[final_df['jobma_catcher_parent'] != 0].groupby('jobma_catcher_parent').size()\n",
    "            final_df['total_sub'] = final_df['jobma_catcher_id'].map(sub_counts).fillna(0).astype(int)\n",
    "        except KeyError as e:\n",
    "            print(f'Error in Total Sub in merging_df: {e}')\n",
    "        except TypeError as e:\n",
    "            print(f'Error of Int Conversion in Total Sub in merging_df: {e}')        \n",
    "    \n",
    "        # For Kits\n",
    "        try:\n",
    "            sub_kits_sum = final_df[final_df['jobma_catcher_parent'] != 0].groupby('jobma_catcher_parent')['number_of_kits'].sum()\n",
    "            kits_mapped = final_df['jobma_catcher_id'].map(sub_kits_sum).fillna(0)\n",
    "            final_df['number_of_kits'] = final_df['number_of_kits'].fillna(0) + kits_mapped\n",
    "            final_df['number_of_kits'] = final_df['number_of_kits'].astype(int)\n",
    "        except KeyError as e:\n",
    "            print(f'Error in Kits in merging_df: {e}')\n",
    "        except TypeError as e:\n",
    "            print(f'Error of Int Conversion in Kits in merging_df: {e}')\n",
    "        \n",
    "        # For Invitations\n",
    "        try:\n",
    "            sub_invitations_sum = final_df[final_df['jobma_catcher_parent'] != 0].groupby('jobma_catcher_parent')['number_of_invitations'].sum()\n",
    "            invitations_mapped = final_df['jobma_catcher_id'].map(sub_invitations_sum).fillna(0)\n",
    "            final_df['number_of_invitations'] = final_df['number_of_invitations'].fillna(0) + invitations_mapped\n",
    "            final_df['number_of_invitations'] = final_df['number_of_invitations'].astype(int)\n",
    "        except KeyError as e:\n",
    "            print(f'Error in Invitations in merging_df: {e}')\n",
    "        except TypeError as e:\n",
    "            print(f'Error of Int Conversion in Invitations in merging_df: {e}')\n",
    "        \n",
    "        # For Job Posted\n",
    "        try:\n",
    "            sub_job_posted_sum = final_df[final_df['jobma_catcher_parent'] != 0].groupby('jobma_catcher_parent')['job_posted'].sum()\n",
    "            job_posted_mapped = final_df['jobma_catcher_id'].map(sub_job_posted_sum).fillna(0)\n",
    "            final_df['job_posted'] = final_df['job_posted'].fillna(0) + job_posted_mapped\n",
    "            final_df['job_posted'] = final_df['job_posted'].astype(int)\n",
    "        except KeyError as e:\n",
    "            print(f'Error in Job Posted in merging_df: {e}')\n",
    "        except TypeError as e:\n",
    "            print(f'Error of Int Conversion in Job Posted in merging_df: {e}')\n",
    "    \n",
    "        # For Recorded Interviews\n",
    "        try:\n",
    "            sub_recorded_sum = final_df[final_df['jobma_catcher_parent'] != 0].groupby('jobma_catcher_parent')['number_of_recorded_interviews'].sum()\n",
    "            recorded_mapped = final_df['jobma_catcher_id'].map(sub_recorded_sum).fillna(0)\n",
    "            final_df['number_of_recorded_interviews'] = final_df['number_of_recorded_interviews'].fillna(0) + recorded_mapped\n",
    "            final_df['number_of_recorded_interviews'] = final_df['number_of_recorded_interviews'].astype(int)\n",
    "        except KeyError as e:\n",
    "            print(f'Error in Recorded Interviews in merging_df: {e}')\n",
    "        except TypeError as e:\n",
    "            print(f'Error of Int Conversion in Recorded Interviews in merging_df: {e}')\n",
    "    \n",
    "        # For Live Interviews\n",
    "        try:\n",
    "            sub_live_sum = final_df[final_df['jobma_catcher_parent'] != 0].groupby('jobma_catcher_parent')['number_of_live_interviews'].sum()\n",
    "            live_mapped = final_df['jobma_catcher_id'].map(sub_live_sum).fillna(0)\n",
    "            final_df['number_of_live_interviews'] = final_df['number_of_live_interviews'].fillna(0) + live_mapped\n",
    "            final_df['number_of_live_interviews'] = final_df['number_of_live_interviews'].astype(int)\n",
    "        except KeyError as e:\n",
    "            print(f'Error in Live Interviews in merging_df: {e}')\n",
    "        except TypeError as e:\n",
    "            print(f'Error of Int Conversion in Live Interviews in merging_df: {e}')\n",
    "    \n",
    "        # For Interview Completed\n",
    "        try:\n",
    "            sub_to_parent_sum = final_df[final_df['jobma_catcher_parent'] != 0].groupby('jobma_catcher_parent')['interview_completed'].sum()\n",
    "            final_df.loc[final_df['jobma_catcher_id'].isin(sub_to_parent_sum.index), 'interview_completed'] += final_df['jobma_catcher_id'].map(sub_to_parent_sum).fillna(0).astype(int)\n",
    "        except KeyError as e:\n",
    "            print(f'Error in Live Interviews in merging_df: {e}')\n",
    "        except TypeError as e:\n",
    "            print(f'Error of Int Conversion in Live Interviews in merging_df: {e}')\n",
    "        \n",
    "        # For Minimum Login Days\n",
    "        try:\n",
    "            login_order = {\n",
    "                'Less than 1 Week':0,\n",
    "                '1-4 Weeks':1,\n",
    "                '1-3 Months':2,\n",
    "                '3-6 Months':3,\n",
    "                '6-12 Months':4,\n",
    "                'More than 1 Year':5\n",
    "            }\n",
    "        \n",
    "            # For Login\n",
    "            final_df['activity_duration'] = final_df['activity_duration'].map(login_order).fillna(5).astype(int)\n",
    "            # It will calculate the minimum activity of subcatcher\n",
    "            sub_min_login = final_df[final_df['jobma_catcher_parent'] != 0].groupby('jobma_catcher_parent')['activity_duration'].min()\n",
    "            catcher_mask = final_df['jobma_catcher_id'].isin(sub_min_login.index)\n",
    "            final_df.loc[catcher_mask, 'activity_duration'] = np.minimum(\n",
    "                final_df.loc[catcher_mask, 'activity_duration'],\n",
    "                final_df.loc[catcher_mask, 'jobma_catcher_id'].map(sub_min_login)\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f'Error in Login in merging_df: {e}')\n",
    "    \n",
    "        df = final_df[final_df['jobma_catcher_parent'] == 0].copy()\n",
    "        df.drop(['jobma_catcher_parent'], axis=1, inplace=True)\n",
    "        \n",
    "        compare_df = df.copy()\n",
    "        df.drop('jobma_catcher_id', axis=1, inplace=True)\n",
    "    \n",
    "        print(f\"Final merged df shape is {df.shape}\")\n",
    "    \n",
    "        return df, compare_df\n",
    "    except Exception as e:\n",
    "        print(f'Key Not Found: {e}')\n",
    "\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92ee37a5-973e-497e-9ad1-c186d842937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(final_df):\n",
    "    final_df = final_df.copy()\n",
    "\n",
    "    # Step 1: Replace inf with NaN first\n",
    "    try: \n",
    "        final_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "        # Step 2: Fill NaNs\n",
    "        fill_values = {\n",
    "            'subscription_status': 0,\n",
    "            'company_size': '1-25',\n",
    "            'activity_duration': 5,\n",
    "            'is_unlimited': 0,\n",
    "            'subscription_amount_in_dollars': 0,\n",
    "            'number_of_subscriptions': 0,\n",
    "            'number_of_invitations': 0,\n",
    "            'number_of_recorded_interviews': 0,\n",
    "            'number_of_live_interviews': 0,\n",
    "            'interview_completed': 0,\n",
    "            'job_posted': 0,\n",
    "            'number_of_kits': 0,\n",
    "            'total_sub': 0,\n",
    "        }\n",
    "        final_df.fillna(fill_values, inplace=True)\n",
    "        \n",
    "    except KeyError as e:\n",
    "        print(f'Key Not Found: {e}')\n",
    "    except Exception as e:\n",
    "        print(f'Error during fillna step: {e}')\n",
    "\n",
    "    # Step 3: Explicitly cast to int for the appropriate columns\n",
    "    try:\n",
    "        int_columns = [\n",
    "            'subscription_status',\n",
    "            'activity_duration',\n",
    "            'is_unlimited',\n",
    "            'number_of_subscriptions',\n",
    "            'number_of_invitations',\n",
    "            'number_of_recorded_interviews',\n",
    "            'number_of_live_interviews',\n",
    "            'interview_completed',\n",
    "            'job_posted',\n",
    "            'number_of_kits',\n",
    "            'total_sub',\n",
    "        ]\n",
    "        \n",
    "        for col in int_columns:\n",
    "            if col in final_df.columns:\n",
    "                final_df[col] = pd.to_numeric(final_df[col], errors='coerce').fillna(0).astype(int)\n",
    "            else:\n",
    "                print(f'Column {col} not found in DataFrame')\n",
    "    except Exception as e:\n",
    "        print(f'Error during Int Conversion: {e}')\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61e7b3bc-8d31-4846-8d24-5a3611a2d1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Encoding \n",
    "def ordinal_encoder(df):\n",
    "    try:\n",
    "        ordinal_col = ['company_size']\n",
    "        company_size_order = ['1-25', '26-100', '101-500', '500-1000', 'More than 1000']\n",
    "    \n",
    "        ordinal = OrdinalEncoder(categories=[company_size_order])\n",
    "    \n",
    "        # encoded = ordinal.fit_transform(df[ordinal_col].astype(str))\n",
    "        encoded = ordinal.fit_transform(df[ordinal_col])\n",
    "    \n",
    "        encoded_df = pd.DataFrame(encoded, columns=[f' {col}_ord' for col in ordinal_col], index=df.index)\n",
    "    \n",
    "        df.drop(columns=ordinal_col, inplace=True)\n",
    "    \n",
    "        df = pd.concat([df, encoded_df], axis=1)\n",
    "        return df\n",
    "        \n",
    "    except KeyError as e:\n",
    "        print(f\"Missing column in the input DataFrame: {e}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'Error in ordinal_encoder: {e}')\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da2d101c-fb7b-4a8b-b7cb-a5bdb5d37183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Transformation\n",
    "def log_transform(df):\n",
    "    log_cols = [\n",
    "            'subscription_amount_in_dollars',\n",
    "            'number_of_subscriptions',\n",
    "            'interview_completed',\n",
    "            'number_of_invitations',\n",
    "            'number_of_recorded_interviews',\n",
    "            'number_of_live_interviews',\n",
    "            'job_posted',\n",
    "            'number_of_kits',\n",
    "            'activity_duration',\n",
    "            'total_sub'\n",
    "        ]\n",
    "\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(\"Error: Input received in Log Transformation is not a DataFrame.\")\n",
    "        return df\n",
    "\n",
    "    if not log_cols:\n",
    "        print(\"Log columns list is empty.\")\n",
    "        return df\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    for col in log_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna(0)        # Handle NaNs\n",
    "            df[col] = df[col].clip(lower=0)    # if a number is less than zero, turn it into zero\n",
    "            df[col] = np.log1p(df[col])        # Apply log1p safely\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ce9113a-2412-4dc8-9fa6-9f0bde47fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will only work if the input this function is receiving is \"Numpy Array\".\n",
    "def to_tensor(x):\n",
    "    try:\n",
    "        if isinstance(x, np.ndarray):\n",
    "            return torch.tensor(x, dtype=torch.float32)\n",
    "        else:\n",
    "            raise TypeError('Input is Not Numpy Array')\n",
    "    except TypeError as e:\n",
    "        print(f\"Error Converting Values to Tensors: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c60a9f7-f3f9-463b-ae85-65370ce5ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MergingTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        engine = create_connection()\n",
    "        wallet_df,subscription_df,invitation_df,job_posting_df,kit_df, login_df = create_df(engine)\n",
    "        self.wallet_df = wallet_df\n",
    "        self.subscription_df = subscription_df\n",
    "        self.invitation_df = invitation_df\n",
    "        self.job_posting_df = job_posting_df\n",
    "        self.kit_df = kit_df\n",
    "        self.login_df = login_df\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, catcher_df):\n",
    "        catcher = fetching_catcher_df(catcher_df)\n",
    "        wallet = fetching_wallet_df(self.wallet_df)\n",
    "        subscription = fetching_subscription_df(self.subscription_df)\n",
    "        login = fetching_login_df(self.login_df)\n",
    "        invitation, job_posting, kit = fetching_features(\n",
    "            self.invitation_df,\n",
    "            self.job_posting_df,\n",
    "            self.kit_df,\n",
    "        )\n",
    "        final_df, compare_df = merging_df(catcher, wallet, subscription, invitation, job_posting, kit, login)\n",
    "        self.compare_df_ = fill_missing_values(compare_df)\n",
    "        self.compare_df_.to_csv(\"compare_df.csv\", index=False)\n",
    "        return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb8075f4-1e34-41b7-8ccc-5fb2d9323ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessingTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = fill_missing_values(X)\n",
    "        X = ordinal_encoder(X)\n",
    "        X = log_transform(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e9382c5-a2e8-4451-af61-1c6d66c89ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_shape, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32)  # bottleneck\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, input_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        encoded = self.encoder(X)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6b317f7-5850-43fa-bc29-0dcbb195399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae91c800-27cd-4224-9a34-5a8d272f95ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_model():\n",
    "    print(\"Starting with model training\")\n",
    "\n",
    "    try:\n",
    "        # Pipelines\n",
    "        merge_pipeline = Pipeline([\n",
    "            ('merge', MergingTransformer())\n",
    "        ])\n",
    "    \n",
    "        # Step 2: Preprocess merged data\n",
    "        preprocess_pipeline = Pipeline([\n",
    "            ('preprocessing', PreprocessingTransformer()),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('to_tensor', FunctionTransformer(to_tensor))\n",
    "        ])\n",
    "    \n",
    "        full_pipeline = Pipeline([\n",
    "            ('merge_pipeline', merge_pipeline),\n",
    "            ('preprocess_pipeline', preprocess_pipeline)\n",
    "        ])\n",
    "    \n",
    "        X_tensor = full_pipeline.fit_transform(create_df(create_connection(),catcher_only=True))\n",
    "        \n",
    "        with open('full_pipeline.pkl', 'wb') as f:\n",
    "            pickle.dump(full_pipeline, f)\n",
    "        \n",
    "        X_df = pd.DataFrame(X_tensor)\n",
    "        X_data = CustomDataset(X_tensor)\n",
    "    \n",
    "        # BATCH_SIZE = 32\n",
    "        BATCH_SIZE = 16\n",
    "        dataloader = DataLoader(X_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "        # Initializing the Model \n",
    "        input_shape = X_df.shape[1]\n",
    "        model_1 = AutoEncoder(input_shape)\n",
    "    \n",
    "        # Important Parameters \n",
    "        learning_rate = 0.001\n",
    "        epochs = 100\n",
    "        # epochs = 50\n",
    "        patience = 5\n",
    "        delta = 1e-4\n",
    "        best_loss = float('inf')\n",
    "        epochs_no_improve = 0\n",
    "        training_losses = []\n",
    "    \n",
    "        # Loss Function, Optimizers and LR Scheduler \n",
    "        loss_function = nn.SmoothL1Loss()\n",
    "        optimizer = torch.optim.AdamW(model_1.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            model_1.train()\n",
    "            epoch_loss = 0\n",
    "    \n",
    "            for batch in dataloader:\n",
    "                encoded, decoded = model_1(batch)\n",
    "                loss = loss_function(decoded, batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "                epoch_loss += loss.item()\n",
    "    \n",
    "            avg_loss = epoch_loss / len(dataloader)\n",
    "            training_losses.append(avg_loss)\n",
    "            scheduler.step(avg_loss)\n",
    "    \n",
    "            print(f\"Epoch: {epoch+1}/{epochs} | Loss: {avg_loss:.6f}\")\n",
    "    \n",
    "            # Early Stopping\n",
    "            if avg_loss < best_loss - delta:\n",
    "                best_loss = avg_loss\n",
    "                epochs_no_improve = 0\n",
    "    \n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve >= patience:\n",
    "                    print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                    break\n",
    "    \n",
    "            # Print current learning rate\n",
    "            for param_group in optimizer.param_groups:\n",
    "                print(f\"Learning Rate: {param_group['lr']:.6f}\")\n",
    "        print(\"Saving Model and Embeddings\")\n",
    "        torch.save(model_1.state_dict(),'model.pth')\n",
    "        encoder, _ = model_1(X_tensor)\n",
    "        latent_np = encoder.cpu().detach().numpy()\n",
    "    \n",
    "        with open('latent_np.pkl', 'wb') as embeddings_file:\n",
    "            pickle.dump(latent_np, embeddings_file)\n",
    "    \n",
    "        print(\"Model and Embeddings Saved\")\n",
    "    except Exception as e:\n",
    "        print(f'Error in Training: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7df1a6b2-0fc3-44fa-9ee4-fadb5fa07c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expecting catcher_id to fetch all the details of user\n",
    "\n",
    "def predict_using_catcher_id(catcher_id, n=5):\n",
    "\n",
    "    #For Minimum Login Days\n",
    "    login_order = {\n",
    "        'Less than 1 Week':0,\n",
    "        '1-4 Weeks':1,\n",
    "        '1-3 Months':2,\n",
    "        '3-6 Months':3,\n",
    "        '6-12 Months':4,\n",
    "        'More than 1 Year':5\n",
    "    }\n",
    "    \n",
    "    # Load the full pipeline and model\n",
    "    with open('full_pipeline.pkl', 'rb') as f:\n",
    "        full_pipeline = pickle.load(f)\n",
    "\n",
    "    # Extract Pipelines\n",
    "    preprocess_pipeline = full_pipeline.named_steps['preprocess_pipeline']\n",
    "    compare_df = pd.read_csv('compare_df.csv')\n",
    "\n",
    "    # Get the row corresponding to the input catcher_id\n",
    "    user_row = compare_df[compare_df['jobma_catcher_id'] == catcher_id]\n",
    "    print(user_row)\n",
    "\n",
    "    # Exception Handling\n",
    "    try:\n",
    "        if user_row.empty:\n",
    "            raise ValueError(f\"No data found for catcher_id: {catcher_id}\")\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    user_input = user_row.drop(columns=['jobma_catcher_id']).iloc[0].to_dict()\n",
    "    user_df = pd.DataFrame([user_input])\n",
    "    transformed_input = preprocess_pipeline.transform(user_df)\n",
    "\n",
    "    # Load trained autoencoder model\n",
    "    input_shape = transformed_input.shape[1]\n",
    "    model_1 = AutoEncoder(input_shape)\n",
    "    model_1.load_state_dict(torch.load('model.pth'))\n",
    "    model_1.eval()\n",
    "\n",
    "    # Load latent embeddings\n",
    "    with open('latent_np.pkl', 'rb') as embeddings_file:\n",
    "        embeddings = pickle.load(embeddings_file)\n",
    "\n",
    "    # Generate user embedding\n",
    "    with torch.no_grad():\n",
    "        user_embedding, _ = model_1(torch.tensor(transformed_input, dtype=torch.float32))\n",
    "        user_embedding = F.normalize(user_embedding, p=2, dim=1)\n",
    "\n",
    "        latent_embeddings_tensor = torch.tensor(embeddings, dtype=torch.float32)\n",
    "        latent_embeddings = F.normalize(latent_embeddings_tensor, p=2, dim=1)\n",
    "\n",
    "        # Compute cosine similarity and get top n+1 (to account for the input catcher_id)\n",
    "        similarities = F.cosine_similarity(user_embedding, latent_embeddings, dim=1)\n",
    "        top_indices = similarities.topk(n + 1).indices.cpu().numpy()\n",
    "\n",
    "    # Final Recommendation DataFrame\n",
    "    recommended = compare_df.iloc[top_indices].copy()\n",
    "\n",
    "    # Drop the row corresponding to the input catcher_id\n",
    "    recommended = recommended[recommended['jobma_catcher_id'] != catcher_id]\n",
    "\n",
    "    # Ensure exactly 'n' rows are returned\n",
    "    recommended = recommended.head(n)\n",
    "\n",
    "    # Add similarity score to the recommendations\n",
    "    recommended['similarity'] = similarities[top_indices[:len(recommended)]].cpu().numpy()[:len(recommended)]\n",
    "\n",
    "    # Replace encoded activity_duration with actual values\n",
    "    recommended['activity_duration'] = recommended['activity_duration'].replace({v: k for k, v in login_order.items()})\n",
    "\n",
    "    return recommended\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce34447a-2228-4b66-b36e-8bbbbc8ea203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expecting all details from user_input\n",
    "\n",
    "def predict(user_input, n=5):\n",
    "\n",
    "    #For Minimum Login Days\n",
    "    login_order = {\n",
    "        'Less than 1 Week':0,\n",
    "        '1-4 Weeks':1,\n",
    "        '1-3 Months':2,\n",
    "        '3-6 Months':3,\n",
    "        '6-12 Months':4,\n",
    "        'More than 1 Year':5\n",
    "    }\n",
    "    \n",
    "    with open('full_pipeline.pkl', 'rb') as f:\n",
    "        full_pipeline = pickle.load(f)\n",
    "\n",
    "    # Extract pipelines\n",
    "    preprocess_pipeline = full_pipeline.named_steps['preprocess_pipeline']\n",
    "\n",
    "    # access compare_df using .csv file instead of fetching it from database\n",
    "    compare_df = pd.read_csv('compare_df.csv')\n",
    "\n",
    "    # Transform user input only with preprocessing pipeline\n",
    "    user_df = pd.DataFrame([user_input])\n",
    "    transformed_input = preprocess_pipeline.transform(user_df)\n",
    "    print(f'Transformed User Input Type is: {type(transformed_input)}')\n",
    "\n",
    "    # Load trained model\n",
    "    input_shape = transformed_input.shape[1]\n",
    "    model_1 = AutoEncoder(input_shape)\n",
    "    model_1.load_state_dict(torch.load('model.pth'))\n",
    "    model_1.eval()\n",
    "\n",
    "    # Load latent embeddings\n",
    "    with open('latent_np.pkl', 'rb') as embeddings_file:\n",
    "        embeddings = pickle.load(embeddings_file)\n",
    "    print(f'Embedding Type is {type(embeddings)}')\n",
    "    \n",
    "    # Generate user embedding\n",
    "    with torch.no_grad():\n",
    "        user_embedding, _ = model_1(transformed_input)\n",
    "        user_embedding = F.normalize(user_embedding, p=2, dim=1)\n",
    "        print(f'User Embedding Type is: {type(user_embedding)}')\n",
    "\n",
    "        latent_embeddings_tensor = torch.tensor(embeddings, dtype=torch.float32)\n",
    "        latent_embeddings = F.normalize(latent_embeddings_tensor, p=2, dim=1)\n",
    "        print(f'Latent Embedding Type is {type(latent_embeddings)}')\n",
    "\n",
    "        # Compute cosine similarity and get top-N\n",
    "        similarities = F.cosine_similarity(user_embedding, latent_embeddings, dim=1)\n",
    "        top_indices = similarities.topk(n).indices.cpu().numpy()\n",
    "    \n",
    "    # Final Recommendation DataFrame\n",
    "    recommended = compare_df.iloc[top_indices].copy()\n",
    "    \n",
    "    # To show the actual activity duration\n",
    "    recommended['activity_duration'] = recommended['activity_duration'].replace({v:k for k,v in login_order.items()})\n",
    "\n",
    "    # To show the Similarity Score\n",
    "    recommended['similarity'] = similarities[top_indices].cpu().numpy()\n",
    "    print(user_pref_good)\n",
    "    \n",
    "    return recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea0d4d99-f35d-4fb9-9d55-4e8186e994a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pref_good = {\n",
    "                 'subscription_status':0,\n",
    "                 'company_size':'101-500',\n",
    "                'activity_duration':4,\n",
    "                 'is_unlimited':0,\n",
    "                 'subscription_amount_in_dollars': 100.00,\n",
    "                 'number_of_subscriptions':1,\n",
    "                 'number_of_invitations':25,\n",
    "                'number_of_recorded_interviews':8,\n",
    "                'number_of_live_interviews':5,\n",
    "                'interview_completed':10,\n",
    "                'job_posted':4,\n",
    "                'number_of_kits':7,\n",
    "                'total_sub':1,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1669beda-3ee5-4454-9c3d-5d60d087f65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pref_test = {\n",
    "                  'subscription_status':1,\n",
    "                'company_size':'1-25',\n",
    "                  'activity_duration':3,\n",
    "                 'is_unlimited':1,\n",
    "                 'subscription_amount_in_dollars': 125.0,\n",
    "                 'number_of_subscriptions':1,\n",
    "                 'number_of_invitations':18,\n",
    "                  'number_of_recorded_interviews':523,\n",
    "                'number_of_live_interviews':1,\n",
    "                'interview_completed':10,\n",
    "                 'job_posted':1,\n",
    "                 'number_of_kits':1,\n",
    "                'total_sub':1\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88b760a2-d964-4379-aab3-29b169a708a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with model training\n",
      "creating connection with DB\n",
      "connection created successfully\n",
      "creating DFs=============\n",
      "Wallet DF\n",
      "Subscription DF\n",
      "Invitation DF\n",
      "Job posting DF\n",
      "kit DF\n",
      "Login DF\n",
      "creating connection with DB\n",
      "connection created successfully\n",
      "creating DFs=============\n",
      "Catcher DF is requested\n",
      "Processing catcher DF\n",
      "Processing wallet DF\n",
      "Processing subscription DF\n",
      "Processing login DF\n",
      "Fetching features\n",
      "Merging DFs\n",
      "Final merged df shape is (4464, 13)\n",
      "Epoch: 1/100 | Loss: 0.139597\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 2/100 | Loss: 0.078942\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 3/100 | Loss: 0.066398\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 4/100 | Loss: 0.059368\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 5/100 | Loss: 0.053510\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 6/100 | Loss: 0.050220\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 7/100 | Loss: 0.048833\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 8/100 | Loss: 0.045025\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 9/100 | Loss: 0.042856\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 10/100 | Loss: 0.041832\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 11/100 | Loss: 0.039808\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 12/100 | Loss: 0.039873\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 13/100 | Loss: 0.039277\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 14/100 | Loss: 0.036419\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 15/100 | Loss: 0.034855\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 16/100 | Loss: 0.030938\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 17/100 | Loss: 0.029627\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 18/100 | Loss: 0.028094\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 19/100 | Loss: 0.027594\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 20/100 | Loss: 0.027738\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 21/100 | Loss: 0.027110\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 22/100 | Loss: 0.026432\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 23/100 | Loss: 0.025268\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 24/100 | Loss: 0.025452\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 25/100 | Loss: 0.024177\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 26/100 | Loss: 0.023969\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 27/100 | Loss: 0.023638\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 28/100 | Loss: 0.024871\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 29/100 | Loss: 0.024319\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 30/100 | Loss: 0.023094\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 31/100 | Loss: 0.023791\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 32/100 | Loss: 0.022659\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 33/100 | Loss: 0.022408\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 34/100 | Loss: 0.023116\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 35/100 | Loss: 0.022110\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 36/100 | Loss: 0.020972\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 37/100 | Loss: 0.021615\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 38/100 | Loss: 0.020449\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 39/100 | Loss: 0.019416\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 40/100 | Loss: 0.020281\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 41/100 | Loss: 0.020662\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 42/100 | Loss: 0.019555\n",
      "Learning Rate: 0.001000\n",
      "Epoch: 43/100 | Loss: 0.019596\n",
      "Learning Rate: 0.000500\n",
      "Epoch: 44/100 | Loss: 0.015884\n",
      "Learning Rate: 0.000500\n",
      "Epoch: 45/100 | Loss: 0.014767\n",
      "Learning Rate: 0.000500\n",
      "Epoch: 46/100 | Loss: 0.014583\n",
      "Learning Rate: 0.000500\n",
      "Epoch: 47/100 | Loss: 0.013861\n",
      "Learning Rate: 0.000500\n",
      "Epoch: 48/100 | Loss: 0.013841\n",
      "Learning Rate: 0.000500\n",
      "Epoch: 49/100 | Loss: 0.014573\n",
      "Learning Rate: 0.000500\n",
      "Epoch: 50/100 | Loss: 0.014389\n",
      "Learning Rate: 0.000500\n",
      "Epoch: 51/100 | Loss: 0.014081\n",
      "Learning Rate: 0.000500\n",
      "Epoch: 52/100 | Loss: 0.014946\n",
      "Early stopping triggered at epoch 52\n",
      "Saving Model and Embeddings\n",
      "Model and Embeddings Saved\n"
     ]
    }
   ],
   "source": [
    "train_and_save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08acb270-79a5-487d-86ac-6f872b2756e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed User Input Type is: <class 'torch.Tensor'>\n",
      "Embedding Type is <class 'numpy.ndarray'>\n",
      "User Embedding Type is: <class 'torch.Tensor'>\n",
      "Latent Embedding Type is <class 'torch.Tensor'>\n",
      "{'subscription_status': 0, 'company_size': '101-500', 'activity_duration': 4, 'is_unlimited': 0, 'subscription_amount_in_dollars': 100.0, 'number_of_subscriptions': 1, 'number_of_invitations': 25, 'number_of_recorded_interviews': 8, 'number_of_live_interviews': 5, 'interview_completed': 10, 'job_posted': 4, 'number_of_kits': 7, 'total_sub': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobma_catcher_id</th>\n",
       "      <th>subscription_status</th>\n",
       "      <th>company_size</th>\n",
       "      <th>activity_duration</th>\n",
       "      <th>is_unlimited</th>\n",
       "      <th>subscription_amount_in_dollars</th>\n",
       "      <th>number_of_subscriptions</th>\n",
       "      <th>number_of_invitations</th>\n",
       "      <th>number_of_recorded_interviews</th>\n",
       "      <th>number_of_live_interviews</th>\n",
       "      <th>interview_completed</th>\n",
       "      <th>job_posted</th>\n",
       "      <th>number_of_kits</th>\n",
       "      <th>total_sub</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4427</th>\n",
       "      <td>10482</td>\n",
       "      <td>1</td>\n",
       "      <td>101-500</td>\n",
       "      <td>6-12 Months</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4303</th>\n",
       "      <td>10297</td>\n",
       "      <td>1</td>\n",
       "      <td>101-500</td>\n",
       "      <td>6-12 Months</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.919626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4406</th>\n",
       "      <td>10442</td>\n",
       "      <td>1</td>\n",
       "      <td>26-100</td>\n",
       "      <td>6-12 Months</td>\n",
       "      <td>0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "      <td>128</td>\n",
       "      <td>6</td>\n",
       "      <td>123</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0.905040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>10199</td>\n",
       "      <td>1</td>\n",
       "      <td>500-1000</td>\n",
       "      <td>6-12 Months</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>436</td>\n",
       "      <td>427</td>\n",
       "      <td>9</td>\n",
       "      <td>408</td>\n",
       "      <td>35</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>0.893872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4208</th>\n",
       "      <td>10142</td>\n",
       "      <td>1</td>\n",
       "      <td>500-1000</td>\n",
       "      <td>6-12 Months</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>73</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0.860613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      jobma_catcher_id  subscription_status company_size activity_duration  \\\n",
       "4427             10482                    1      101-500       6-12 Months   \n",
       "4303             10297                    1      101-500       6-12 Months   \n",
       "4406             10442                    1       26-100       6-12 Months   \n",
       "4241             10199                    1     500-1000       6-12 Months   \n",
       "4208             10142                    1     500-1000       6-12 Months   \n",
       "\n",
       "      is_unlimited  subscription_amount_in_dollars  number_of_subscriptions  \\\n",
       "4427             0                           100.0                        1   \n",
       "4303             0                           100.0                        1   \n",
       "4406             0                           150.0                        1   \n",
       "4241             0                             0.0                        1   \n",
       "4208             0                            50.0                        1   \n",
       "\n",
       "      number_of_invitations  number_of_recorded_interviews  \\\n",
       "4427                     29                             22   \n",
       "4303                     28                             21   \n",
       "4406                    134                            128   \n",
       "4241                    436                            427   \n",
       "4208                     73                             68   \n",
       "\n",
       "      number_of_live_interviews  interview_completed  job_posted  \\\n",
       "4427                          7                   18           4   \n",
       "4303                          7                   19           3   \n",
       "4406                          6                  123          16   \n",
       "4241                          9                  408          35   \n",
       "4208                          5                   73          16   \n",
       "\n",
       "      number_of_kits  total_sub  similarity  \n",
       "4427               7          1    0.979252  \n",
       "4303               9          1    0.919626  \n",
       "4406              31          2    0.905040  \n",
       "4241              66          3    0.893872  \n",
       "4208              32          2    0.860613  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(user_pref_good, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d65ae01-8a57-4538-abf4-6f962de05c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed User Input Type is: <class 'torch.Tensor'>\n",
      "Embedding Type is <class 'numpy.ndarray'>\n",
      "User Embedding Type is: <class 'torch.Tensor'>\n",
      "Latent Embedding Type is <class 'torch.Tensor'>\n",
      "{'subscription_status': 0, 'company_size': '101-500', 'activity_duration': 4, 'is_unlimited': 0, 'subscription_amount_in_dollars': 100.0, 'number_of_subscriptions': 1, 'number_of_invitations': 25, 'number_of_recorded_interviews': 8, 'number_of_live_interviews': 5, 'interview_completed': 10, 'job_posted': 4, 'number_of_kits': 7, 'total_sub': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobma_catcher_id</th>\n",
       "      <th>subscription_status</th>\n",
       "      <th>company_size</th>\n",
       "      <th>activity_duration</th>\n",
       "      <th>is_unlimited</th>\n",
       "      <th>subscription_amount_in_dollars</th>\n",
       "      <th>number_of_subscriptions</th>\n",
       "      <th>number_of_invitations</th>\n",
       "      <th>number_of_recorded_interviews</th>\n",
       "      <th>number_of_live_interviews</th>\n",
       "      <th>interview_completed</th>\n",
       "      <th>job_posted</th>\n",
       "      <th>number_of_kits</th>\n",
       "      <th>total_sub</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>10524</td>\n",
       "      <td>1</td>\n",
       "      <td>26-100</td>\n",
       "      <td>6-12 Months</td>\n",
       "      <td>0</td>\n",
       "      <td>293.324</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.892164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>10505</td>\n",
       "      <td>1</td>\n",
       "      <td>1-25</td>\n",
       "      <td>6-12 Months</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.888602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4463</th>\n",
       "      <td>10536</td>\n",
       "      <td>1</td>\n",
       "      <td>1-25</td>\n",
       "      <td>6-12 Months</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.872796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>10525</td>\n",
       "      <td>1</td>\n",
       "      <td>26-100</td>\n",
       "      <td>6-12 Months</td>\n",
       "      <td>1</td>\n",
       "      <td>117.330</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>10438</td>\n",
       "      <td>1</td>\n",
       "      <td>101-500</td>\n",
       "      <td>6-12 Months</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.860981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      jobma_catcher_id  subscription_status company_size activity_duration  \\\n",
       "4455             10524                    1       26-100       6-12 Months   \n",
       "4437             10505                    1         1-25       6-12 Months   \n",
       "4463             10536                    1         1-25       6-12 Months   \n",
       "4456             10525                    1       26-100       6-12 Months   \n",
       "4402             10438                    1      101-500       6-12 Months   \n",
       "\n",
       "      is_unlimited  subscription_amount_in_dollars  number_of_subscriptions  \\\n",
       "4455             0                         293.324                        1   \n",
       "4437             0                         100.000                        1   \n",
       "4463             0                           0.000                        1   \n",
       "4456             1                         117.330                        1   \n",
       "4402             0                         100.000                        1   \n",
       "\n",
       "      number_of_invitations  number_of_recorded_interviews  \\\n",
       "4455                      1                              1   \n",
       "4437                      0                              0   \n",
       "4463                      2                              2   \n",
       "4456                      0                              0   \n",
       "4402                      4                              4   \n",
       "\n",
       "      number_of_live_interviews  interview_completed  job_posted  \\\n",
       "4455                          0                    1           1   \n",
       "4437                          0                    0           0   \n",
       "4463                          0                    2           1   \n",
       "4456                          0                    0           1   \n",
       "4402                          0                    4           2   \n",
       "\n",
       "      number_of_kits  total_sub  similarity  \n",
       "4455               1          0    0.892164  \n",
       "4437               0          0    0.888602  \n",
       "4463               1          0    0.872796  \n",
       "4456               1          0    0.866946  \n",
       "4402               1          0    0.860981  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(user_pref_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "155043c5-8a56-4105-8bd3-b4b13482944f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      jobma_catcher_id  subscription_status company_size  activity_duration  \\\n",
      "1971              6025                    0       26-100                  5   \n",
      "\n",
      "      is_unlimited  subscription_amount_in_dollars  number_of_subscriptions  \\\n",
      "1971             0                           399.0                        1   \n",
      "\n",
      "      number_of_invitations  number_of_recorded_interviews  \\\n",
      "1971                     41                             39   \n",
      "\n",
      "      number_of_live_interviews  interview_completed  job_posted  \\\n",
      "1971                          2                   41           2   \n",
      "\n",
      "      number_of_kits  total_sub  \n",
      "1971               8          1  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobma_catcher_id</th>\n",
       "      <th>subscription_status</th>\n",
       "      <th>company_size</th>\n",
       "      <th>activity_duration</th>\n",
       "      <th>is_unlimited</th>\n",
       "      <th>subscription_amount_in_dollars</th>\n",
       "      <th>number_of_subscriptions</th>\n",
       "      <th>number_of_invitations</th>\n",
       "      <th>number_of_recorded_interviews</th>\n",
       "      <th>number_of_live_interviews</th>\n",
       "      <th>interview_completed</th>\n",
       "      <th>job_posted</th>\n",
       "      <th>number_of_kits</th>\n",
       "      <th>total_sub</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>5930</td>\n",
       "      <td>0</td>\n",
       "      <td>26-100</td>\n",
       "      <td>More than 1 Year</td>\n",
       "      <td>0</td>\n",
       "      <td>224.287</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.992317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>6180</td>\n",
       "      <td>0</td>\n",
       "      <td>26-100</td>\n",
       "      <td>More than 1 Year</td>\n",
       "      <td>0</td>\n",
       "      <td>548.000</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>5974</td>\n",
       "      <td>0</td>\n",
       "      <td>101-500</td>\n",
       "      <td>More than 1 Year</td>\n",
       "      <td>0</td>\n",
       "      <td>207.673</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.948184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>5949</td>\n",
       "      <td>0</td>\n",
       "      <td>1-25</td>\n",
       "      <td>More than 1 Year</td>\n",
       "      <td>0</td>\n",
       "      <td>207.673</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.947039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>5898</td>\n",
       "      <td>0</td>\n",
       "      <td>26-100</td>\n",
       "      <td>More than 1 Year</td>\n",
       "      <td>0</td>\n",
       "      <td>2076.734</td>\n",
       "      <td>6</td>\n",
       "      <td>905</td>\n",
       "      <td>898</td>\n",
       "      <td>3</td>\n",
       "      <td>901</td>\n",
       "      <td>20</td>\n",
       "      <td>78</td>\n",
       "      <td>4</td>\n",
       "      <td>0.934776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      jobma_catcher_id  subscription_status company_size activity_duration  \\\n",
       "1913              5930                    0       26-100  More than 1 Year   \n",
       "2076              6180                    0       26-100  More than 1 Year   \n",
       "1941              5974                    0      101-500  More than 1 Year   \n",
       "1928              5949                    0         1-25  More than 1 Year   \n",
       "1897              5898                    0       26-100  More than 1 Year   \n",
       "\n",
       "      is_unlimited  subscription_amount_in_dollars  number_of_subscriptions  \\\n",
       "1913             0                         224.287                        2   \n",
       "2076             0                         548.000                        2   \n",
       "1941             0                         207.673                        1   \n",
       "1928             0                         207.673                        1   \n",
       "1897             0                        2076.734                        6   \n",
       "\n",
       "      number_of_invitations  number_of_recorded_interviews  \\\n",
       "1913                     40                             37   \n",
       "2076                     25                             21   \n",
       "1941                     49                             46   \n",
       "1928                     23                             19   \n",
       "1897                    905                            898   \n",
       "\n",
       "      number_of_live_interviews  interview_completed  job_posted  \\\n",
       "1913                          2                   39           3   \n",
       "2076                          2                   23           5   \n",
       "1941                          3                   49           1   \n",
       "1928                          4                   23           1   \n",
       "1897                          3                  901          20   \n",
       "\n",
       "      number_of_kits  total_sub  similarity  \n",
       "1913              10          1    0.992317  \n",
       "2076               8          1    0.988089  \n",
       "1941              11          1    0.948184  \n",
       "1928               5          1    0.947039  \n",
       "1897              78          4    0.934776  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_using_catcher_id(6025, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "271a226d-46ae-473d-b469-13dec87f3350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      jobma_catcher_id  subscription_status company_size  activity_duration  \\\n",
      "2084              6189                    0         1-25                  5   \n",
      "\n",
      "      is_unlimited  subscription_amount_in_dollars  number_of_subscriptions  \\\n",
      "2084             0                         346.122                        1   \n",
      "\n",
      "      number_of_invitations  number_of_recorded_interviews  \\\n",
      "2084                    315                            311   \n",
      "\n",
      "      number_of_live_interviews  interview_completed  job_posted  \\\n",
      "2084                          4                  315          45   \n",
      "\n",
      "      number_of_kits  total_sub  \n",
      "2084              23          0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobma_catcher_id</th>\n",
       "      <th>subscription_status</th>\n",
       "      <th>company_size</th>\n",
       "      <th>activity_duration</th>\n",
       "      <th>is_unlimited</th>\n",
       "      <th>subscription_amount_in_dollars</th>\n",
       "      <th>number_of_subscriptions</th>\n",
       "      <th>number_of_invitations</th>\n",
       "      <th>number_of_recorded_interviews</th>\n",
       "      <th>number_of_live_interviews</th>\n",
       "      <th>interview_completed</th>\n",
       "      <th>job_posted</th>\n",
       "      <th>number_of_kits</th>\n",
       "      <th>total_sub</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2774</th>\n",
       "      <td>7177</td>\n",
       "      <td>0</td>\n",
       "      <td>1-25</td>\n",
       "      <td>More than 1 Year</td>\n",
       "      <td>0</td>\n",
       "      <td>346.122</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3607</th>\n",
       "      <td>8279</td>\n",
       "      <td>0</td>\n",
       "      <td>1-25</td>\n",
       "      <td>More than 1 Year</td>\n",
       "      <td>0</td>\n",
       "      <td>175.994</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.912805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3708</th>\n",
       "      <td>8497</td>\n",
       "      <td>1</td>\n",
       "      <td>1-25</td>\n",
       "      <td>More than 1 Year</td>\n",
       "      <td>0</td>\n",
       "      <td>650.000</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>387</td>\n",
       "      <td>9</td>\n",
       "      <td>396</td>\n",
       "      <td>118</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.895474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4178</th>\n",
       "      <td>10095</td>\n",
       "      <td>1</td>\n",
       "      <td>1-25</td>\n",
       "      <td>More than 1 Year</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.894950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>5994</td>\n",
       "      <td>0</td>\n",
       "      <td>1-25</td>\n",
       "      <td>More than 1 Year</td>\n",
       "      <td>0</td>\n",
       "      <td>346.122</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      jobma_catcher_id  subscription_status company_size activity_duration  \\\n",
       "2774              7177                    0         1-25  More than 1 Year   \n",
       "3607              8279                    0         1-25  More than 1 Year   \n",
       "3708              8497                    1         1-25  More than 1 Year   \n",
       "4178             10095                    1         1-25  More than 1 Year   \n",
       "1953              5994                    0         1-25  More than 1 Year   \n",
       "\n",
       "      is_unlimited  subscription_amount_in_dollars  number_of_subscriptions  \\\n",
       "2774             0                         346.122                        1   \n",
       "3607             0                         175.994                        1   \n",
       "3708             0                         650.000                        2   \n",
       "4178             0                           0.000                        1   \n",
       "1953             0                         346.122                        1   \n",
       "\n",
       "      number_of_invitations  number_of_recorded_interviews  \\\n",
       "2774                     24                             24   \n",
       "3607                      3                              3   \n",
       "3708                    396                            387   \n",
       "4178                     20                             17   \n",
       "1953                     15                             15   \n",
       "\n",
       "      number_of_live_interviews  interview_completed  job_posted  \\\n",
       "2774                          0                   24           6   \n",
       "3607                          0                    3           2   \n",
       "3708                          9                  396         118   \n",
       "4178                          3                   20           9   \n",
       "1953                          0                   15           3   \n",
       "\n",
       "      number_of_kits  total_sub  similarity  \n",
       "2774               2          0    0.988836  \n",
       "3607               2          0    0.912805  \n",
       "3708              99          1    0.895474  \n",
       "4178              11          0    0.894950  \n",
       "1953               3          0    0.887079  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_using_catcher_id(6189, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
