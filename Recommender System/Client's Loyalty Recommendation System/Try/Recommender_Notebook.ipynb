{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5647f89-0a87-4c57-a844-257f4fc516e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import pickle\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Data Encoding and Scaling\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, RobustScaler, StandardScaler, FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Pipeline\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import set_config\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a494ec9-7676-4e91-8995-e145c9c90ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51494237-d6fc-4997-99b6-7298477d97e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql+pymysql://root:dushi%401611@localhost:3306/test_database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "902e07e6-5b8a-4a08-8ba1-066e84e07a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "catcher_df = pd.read_sql('Select * FROM jobma_catcher', con=engine)  # Done  (about catcher's account)\n",
    "wallet_df = pd.read_sql('Select * FROM wallet', con=engine)  # Done  ('subscription type, plan type')\n",
    "subscription_df = pd.read_sql('Select * FROM subscription_history', con=engine)  # Done  (number and amount of subscription bought by the catcher)\n",
    "invitation_df = pd.read_sql('Select * FROM jobma_pitcher_invitations', con=engine)  # Done   (number of invitations sent by the catcher)\n",
    "job_posting_df = pd.read_sql('Select * FROM jobma_employer_job_posting', con=engine) # Done    (number of jobs posted by the catcher)\n",
    "kit_df = pd.read_sql('Select * FROM job_assessment_kit', con=engine) # Done   (number of kits created by the catcher)\n",
    "recorded_interview_df = pd.read_sql('Select * FROM jobma_interviews', con=engine) # Done (number of recorded interviews created by the catcher)\n",
    "live_interview_df = pd.read_sql('Select * FROM jobma_interviews_online', con=engine) # Done (number of live interviews created by the catcher)\n",
    "login_df = pd.read_sql('Select * FROM jobma_login',con=engine)  # Done (To Find number of days catcher didn't logged in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a088775a-298f-4ea7-a887-f8ffee369afc",
   "metadata": {},
   "source": [
    "# Specific Methods\n",
    "\n",
    "**To Fetch Columns from different tables and fitting those functions into Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "878188da-619c-4bcb-b2d4-7ccdf08d93f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' catcher_df '''\n",
    "\n",
    "def fetching_catcher_df(df):\n",
    "    sub_counts = catcher_df[catcher_df['jobma_catcher_parent'] != 0]['jobma_catcher_parent'].value_counts()\n",
    "    parents_df = catcher_df[catcher_df['jobma_catcher_parent'] == 0].copy()\n",
    "    parents_df['total_sub'] = parents_df['jobma_catcher_id'].map(sub_counts).fillna(0).astype(int)\n",
    "    parents_df - parents_df[['jobma_catcher_id', 'is_premium', 'subscription_status', 'company_size', 'total_sub']]\n",
    "    parents_df.drop(parents_df[parents_df['subscription_status'] == '0'].index, inplace=True)\n",
    "    parents_df['is_premium'] = parents_df['is_premium'].replace({'0':0, '1':1})\n",
    "\n",
    "    return parents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62244ab9-feed-491d-94d4-5a3db6cd92df",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' wallet_df '''\n",
    "\n",
    "def fetching_wallet_df(df):\n",
    "    wallet_df.rename(columns={'catcher_id': 'jobma_catcher_id'}, inplace=True)\n",
    "    wallet_df = wallet_df[['jobma_catcher_id', 'is_unlimited']]\n",
    "    wallet_df['is_unlimited'] = wallet_df['is_unlimited'].replace({'0':0, '1':1})\n",
    "    wallet_df.drop(wallet_df[wallet_df['is_unlimited'] == ''].index, inplace=True)\n",
    "    wallet_df.drop_duplicates(inplace=True)\n",
    "\n",
    "    return wallet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0df263e4-9d4c-4bc6-9cca-77ca10b33926",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' subscription_df '''\n",
    "\n",
    "def fetching_subscription_df(df):\n",
    "    subscription_df.rename(columns={'catcher_id': 'jobma_catcher_id'}, inplace=True)\n",
    "    subscription_df.loc[subscription_df['currency'] == '1', 'subscription_amount'] /= 85.23\n",
    "    subscription_df = subscription_df.groupby('jobma_catcher_id').agg(\n",
    "        subscription_amount_in_dollars = ('subscription_amount', 'sum'),\n",
    "        number_of_subscriptions = ('subscription_amount', 'count'),\n",
    "    ).reset_index()\n",
    "    subscription_df.drop_duplicates(inplace=True)\n",
    "\n",
    "    return subscription_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4338415-997f-4948-bd30-a32ea18d0f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' login_df '''\n",
    "\n",
    "def fetching_login_df(df):\n",
    "    login_df = login_df[login_df['jobma_role_id'] == 3].copy()\n",
    "    login_df.rename(columns={'jobma_user_id': 'jobma_catcher_id'}, inplace=True)\n",
    "\n",
    "    # Calculating Number of Gaps between last login and today\n",
    "    login_df['jobma_last_login'] = pd.to_datetime(login_df['jobma_last_login'], errors='coerce')\n",
    "    login_df['days_since_last_login'] = (pd.Timestamp('today') - login_df['jobma_last_login']).dt.days\n",
    "    login_df['days_since_last_login'].fillna(9999, inplace=True)\n",
    "    login_df['days_since_last_login'] = login_df['days_since_last_login'].astype(int)\n",
    "\n",
    "    # Binning\n",
    "    bins = [-1,7,30,90,180,365,float('inf')]\n",
    "    labels = ['Less than 1 Week', '1-4 Weeks', '1-3 Months', '3-6 Months', '6-12 Months', 'More than 1 Year']\n",
    "    login_df['days_since_last_login'] = pd.cut(login_df['days_since_last_login'], bins=bins, labels=labels)\n",
    "    login_df = login_df[['jobma_catcher_id', 'days_since_last_login']]\n",
    "\n",
    "    return login_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e4ced3a-819b-4922-af55-70f67375a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetching_features(invitation_df, job_posting_df, kit_df, recorded_interview_df, live_interview_df):\n",
    "    for df in [invitation_df, job_posting_df, kit_df, recorded_interview_df, live_interview_df]:\n",
    "        if 'catcher_id' in df.columns:\n",
    "            df.rename(columns={'catcher_id': 'jobma_catcher_id'}, inplace=True)\n",
    "\n",
    "    invitation_df['number_of_invitations'] = invitation_df['jobma_catcher_id'].map(invitation_df['jobma_catcher_id'].value_counts())\n",
    "    job_posting_df['job_posted'] = job_posting_df['jobma_catcher_id'].map(job_posting_df['jobma_catcher_id'].value_counts())\n",
    "    kit_df['number_of_kits'] = kit_df['jobma_catcher_id'].map(kit_df['jobma_catcher_id'].value_counts())\n",
    "    recorded_interview_df['number_of_recorded_interviews'] = recorded_interview_df['jobma_catcher_id'].map(recorded_interview_df['jobma_catcher_id'].value_counts())\n",
    "    live_interview_df['number_of_live_interviews'] = live_interview_df['jobma_catcher_id'].map(live_interview_df['jobma_catcher_id'].value_counts())\n",
    "\n",
    "    invitation_df = invitation_df[['jobma_catcher_id', 'number_of_invitations']].drop_duplicates()\n",
    "    job_posting_df = job_posting_df[['jobma_catcher_id', 'job_posted']].drop_duplicates()\n",
    "    kit_df = kit_df[['jobma_catcher_id', 'number_of_kits']].drop_duplicates()\n",
    "    recorded_interview_df = recorded_interview_df[['jobma_catcher_id', 'number_of_recorded_interviews']].drop_duplicates()\n",
    "    live_interview_df = live_interview_df[['jobma_catcher_id', 'number_of_live_interviews']].drop_duplicates()\n",
    "\n",
    "    return invitation_df, job_posting_df, kit_df, recorded_interview_df, live_interview_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28c104ba-cf89-44ae-b5cf-c2c85a9a0881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merging_df(df):\n",
    "    final_df = parents_df.copy()\n",
    "\n",
    "    # Left join each table one by one\n",
    "    final_df = final_df.merge(wallet_df, on='jobma_catcher_id', how='left')\n",
    "    final_df = final_df.merge(subscription_df, on='jobma_catcher_id', how='left')\n",
    "    final_df = final_df.merge(invitation_df, on='jobma_catcher_id', how='left')\n",
    "    final_df = final_df.merge(job_posting_df, on='jobma_catcher_id', how='left')\n",
    "    final_df = final_df.merge(kit_df, on='jobma_catcher_id', how='left')\n",
    "    final_df = final_df.merge(recorded_interview_df, on='jobma_catcher_id', how='left')\n",
    "    final_df = final_df.merge(live_interview_df, on='jobma_catcher_id', how='left')\n",
    "    final_df = final_df.merge(login_df, on='jobma_catcher_id', how='left')\n",
    "    final_df.drop_duplicates(inplace=True)\n",
    "\n",
    "    print(f\"Final merged df shape is {final_df.shape}\")\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2b2801d-f220-4bbe-9c09-15837ca7d60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This Function is to fill all missing values '''\n",
    "\n",
    "def fill_missing_values(df):\n",
    "    final_df = final_df.copy()\n",
    "    fill_values = {\n",
    "        'is_premium': 0,\n",
    "        'subscription_status': 1,\n",
    "        'company_size': 'More than 1000',\n",
    "        'total_sub': 0,\n",
    "        'is_unlimited': 1,\n",
    "        'subscription_amount_in_dollars': 0,\n",
    "        'number_of_subscriptions': 0,\n",
    "        'number_of_invitations': 0,\n",
    "        'job_posted': 0,\n",
    "        'number_of_kits': 0,\n",
    "        'number_of_recorded_interviews': 0,\n",
    "        'number_of_live_interviews': 0,\n",
    "        'days_since_last_login': 'More than 1 Year'\n",
    "    }\n",
    "    return final_df.fillna(fill_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa7537f3-7d52-4519-8ff5-03b5da8b1a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Data Encoding '''\n",
    "\n",
    "def ordinal_encoder(df):\n",
    "    ordinal_col = ['company_size', 'days_since_last_login']\n",
    "    company_size_order = ['1-25', '26-100', '101-500', '500-1000', 'More than 1000']\n",
    "    login_days_order = ['Less than 1 Week', '1-4 Weeks', '1-3 Months', '3-6 Months', '6-12 Months', 'More than 1 Year']\n",
    "\n",
    "    total_order = [company_size_order, login_days_order]\n",
    "    ordinal = OrdinalEncoder(categories=total_order)\n",
    "\n",
    "    encoded = ordinal.fit_transform(final_df[ordinal_col].astype(str))\n",
    "    encoded += 1\n",
    "\n",
    "    encoded_df = pd.DataFrame(encoded, columms=[f' {col}_ord' for col in ordinal_col], index=final_df.index)\n",
    "\n",
    "    final_df.drop(columms=ordinal_col, inplace=True)\n",
    "\n",
    "    df = pd.concat([final_df, encoded_df], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dba4d4c5-4b07-4cbb-97b2-3063aaf1114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Log Transformation '''\n",
    "\n",
    "def log_transform(df):\n",
    "    log_cols = [\n",
    "        'total_sub',\n",
    "        'subscription_amount_in_dollars',\n",
    "        'number_of_subscriptions',\n",
    "        'number_of_invitations',\n",
    "        'job_posted',\n",
    "        'number_of_kits',\n",
    "        'number_of_recorded_interviews',\n",
    "        'number_of_live_interviews',\n",
    "        'days_since_last_login'\n",
    "    ]\n",
    "\n",
    "    df = df.copy()\n",
    "    for col in log_cols:\n",
    "        if col in df.columns:\n",
    "            # fill NaNs\n",
    "            df[col] = df[col].fillna(0)\n",
    "            # if a number is less than zero, turn it into zero\n",
    "            df[col] = df[col].clip(lower=0)\n",
    "            # safe log1p\n",
    "            df[col] = np.log1p(df[col])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe320cd5-fcca-484f-8a77-7508a2963dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''  '''\n",
    "# compare_df = df.copy()\n",
    "# df.drop('jobma_catcher_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7606cc4-020a-44af-a40e-ab08f868c4dc",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b9b388-665c-46ae-8570-a542b25fb544",
   "metadata": {},
   "source": [
    "# Fit Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc195801-b397-41b7-ba22-29fe944c68a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7645a784-c8fa-4fcc-9c00-4899a1455833",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7102d56a-dc20-4f2e-a743-0a59d0f0b7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c90ac3d-ecd0-4996-895e-9cdfc9ac451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339211da-a920-44f8-a672-5be1a7436701",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5735a7c4-9179-4316-adc4-e3211e3e0add",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d018b9b5-be0a-43dd-8bea-5d91a5a414f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b63446-def5-4063-8949-06e4fdbdbb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5b8896-10eb-4b22-9c1a-361a4f4b92e0",
   "metadata": {},
   "source": [
    "# Convert into Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd810c50-e510-4bd7-b0fb-f4c1d3fdaec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.tensor(X_transformed, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7593ec7d-478e-484b-9f8f-2910e565f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6598dd5a-8719-49d0-a59f-e33f80426ca9",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c5beee4e-8cd7-43ba-b498-0f1c564c800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1cacb3-e9a3-420d-882c-1c556610b488",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CustomDataset(X_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15197503-29d2-42e7-a385-4bbcd38a2abf",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3626346f-a4a9-4108-9927-e10f760ed791",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5448259-fef1-4d17-b284-a6116cc369c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = Dataloader(data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d33c296-4894-491d-845c-1726d1224591",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f422698b-506f-472c-a92a-a12b696ab772",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa10cee2-4565-4b19-9ff4-59a732099205",
   "metadata": {},
   "source": [
    "# Define a Model (AutoEncoder in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f76a9099-437e-4242-be0a-3c5be182bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_shape, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, input_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        encoded = self.encoder(X)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c71a279-3789-4986-af16-09267a657ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Initializing the Model '''\n",
    "\n",
    "input_shape = X_df.shape[1]\n",
    "model_1 = AutoEncoder(input_shape)\n",
    "model_1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42e017e-c0bd-40f2-ae4d-b27d55bbc9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
